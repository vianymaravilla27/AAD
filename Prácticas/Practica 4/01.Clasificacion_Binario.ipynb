{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analítica Avanzada de Datos.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación\n",
    "\n",
    "Las técnicas de aprendizaje automático *supervisado* consisten en entrenar un modelo para que opere sobre un conjunto de *características* y prediga una etiqueta utilizando un conjunto de datos que incluye algunos valores de etiqueta ya conocidos. Puedes pensar en esta función así, en la que ***y*** representa la etiqueta que queremos predecir y ***X*** representa el vector de características que el modelo utiliza para predecirla.\n",
    "\n",
    "$$y = f([x_1, x_2, x_3, ...])$$\n",
    "\n",
    "La *clasificación* es una forma de aprendizaje automático supervisado en el que se entrena un modelo para utilizar las características (los valores ***x*** de nuestra función) para predecir una etiqueta (***y***) que calcula la probabilidad de que el caso observado pertenezca a cada una de las clases posibles y predice una etiqueta adecuada. La forma más sencilla de clasificación es la clasificación binaria, en la que la etiqueta es 0 o 1, representando una de dos clases; por ejemplo, \"Verdadero\" o \"Falso\"; \"Interno\" o \"Externo\"; \"Rentable\" o \"No rentable\"; etc.\n",
    "\n",
    "## Clasificación binaria\n",
    "\n",
    "En este notebook, nos centraremos en un ejemplo de *clasificación binaria*, donde el modelo debe predecir una etiqueta que pertenece a una de dos clases. Entrenaremos un clasificador binario para predecir si un paciente debe o no someterse a una prueba de diabetes basándonos en algunos datos médicos.\n",
    "\n",
    "\n",
    "### Explorar los datos\n",
    "Ejecuta la siguiente celda para cargar un archivo CSV de datos de patentes en un marco de datos de **Pandas**:\n",
    "\n",
    "> **Cita**: El dataset sobre diabetes utilizado en este ejercicio se basa en datos recogidos originalmente por el \"National Institute of Diabetes and Digestive and Kidney Diseases\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# cargamos el dataset de prueba\n",
    "diabetes = pd.read_csv('diabetes.csv')\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos datos consisten en información diagnóstica sobre algunos pacientes a los que se les ha realizado la prueba de la diabetes. Desplácese a la derecha si es necesario, y observe que la última columna del conjunto de datos (**Diabético**) contiene el valor ***0*** para los pacientes que dieron negativo en la prueba de la diabetes, y ***1*** para los pacientes que dieron positivo. La mayoría de las demás columnas (Embarazos, Glucosa plasmática, Presión arterial diastólica, etc.) son las características que utilizaremos para predecir la etiqueta **Diabético**.\n",
    "\n",
    "Separemos las características de las etiquetas: llamaremos ***X*** a las características e ***y*** a la etiqueta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Funciones y etiquetas separadas\n",
    "features = ['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']\n",
    "label = 'Diabetic'\n",
    "X, y = diabetes[features].values, diabetes[label].values\n",
    "\n",
    "for n in range(0,4):\n",
    "    print(\"Patient\", str(n+1), \"\\n  Features:\",list(X[n]), \"\\n  Label:\", y[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora comparemos las distribuciones de características para cada valor de etiqueta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "features = ['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']\n",
    "for col in features:\n",
    "    diabetes.boxplot(column=col, by='Diabetic', figsize=(6,6))\n",
    "    plt.title(col)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para algunas de las características, hay una diferencia notable en la distribución para cada valor de etiqueta. En particular, **Pregnancies** y **Age**  muestran distribuciones notablemente diferentes para los pacientes diabéticos que para los no diabéticos. Estas características pueden ayudar a predecir si un paciente es diabético o no.\n",
    "\n",
    "\n",
    "### Dividir los datos¶\n",
    "\n",
    "Nuestro dataset incluye valores conocidos para la etiqueta, por lo que podemos utilizarlo para entrenar un clasificador de forma que encuentre una relación estadística entre las características y el valor de la etiqueta; pero ¿cómo sabremos si nuestro modelo es bueno? Podemos aprovechar que tenemos un gran conjunto de datos con valores de etiqueta conocidos, utilizar sólo una parte para entrenar el modelo y retener otra parte para probar el modelo entrenado, lo que nos permite comparar las etiquetas predichas con las etiquetas ya conocidas del conjunto de prueba.\n",
    "\n",
    "En Python, el paquete **scikit-learn** contiene un gran número de funciones que podemos utilizar para construir un modelo de aprendizaje automático, incluida una función **train_test_split** que garantiza que obtengamos una división estadísticamente aleatoria de los datos de entrenamiento y de prueba. Utilizaremos esta función para dividir los datos en un **70%** para el entrenamiento y retener un **30%** para las pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir los datos entre un 70% y un 30% en conjunto de entrenamiento y conjunto de prueba.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "print ('Training cases: %d\\nTest cases: %d' % (X_train.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenar y evaluar un modelo de clasificación binaria\n",
    "\n",
    "Ahora, ya estamos listos para entrenar nuestro modelo ajustando las características de entrenamiento (**X_train**) a las etiquetas de entrenamiento (**y_train**). Hay varios algoritmos que podemos utilizar para entrenar el modelo. En este ejemplo, utilizaremos la regresión logística, que (a pesar de su nombre) es un algoritmo bien establecido para la clasificación. Además de las características y etiquetas de entrenamiento, tendremos que establecer un parámetro de *regularización*. Esto se utiliza para contrarrestar cualquier sesgo en la muestra, y ayudar a que el modelo generalice bien evitando el sobreajuste del modelo a los datos de entrenamiento.\n",
    "\n",
    "\n",
    "> **Nota**: Los parámetros de los algoritmos de aprendizaje automático suelen denominarse *hiperparámetros* (para un científico de datos, los *parámetros* son valores de los propios datos; los *hiperparámetros* se definen externamente a partir de los datos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Fijar la tasa de regularización\n",
    "reg = 0.01\n",
    "\n",
    "# entrenar un modelo de regresión logística en el conjunto de entrenamiento\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "print (model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que hemos entrenado el modelo con los datos de entrenamiento, podemos utilizar los datos de prueba que retuvimos para evaluar lo bien que predice. Una vez más, **scikit-learn** puede ayudarnos a hacerlo. Empecemos utilizando el modelo para predecir las etiquetas de nuestro conjunto de prueba y comparemos las etiquetas predichas con las etiquetas conocidas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "print('Predicted labels: ', predictions)\n",
    "print('Actual labels:    ' ,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las matrices de etiquetas son demasiado largas para mostrarlas en la salida del notebook, por lo que sólo podemos comparar unos pocos valores. Incluso si imprimimos todas las etiquetas predichas y reales, hay demasiadas como para que esta sea una forma sensata de evaluar el modelo. Afortunadamente, **scikit-learn** proporciona algunas métricas que podemos utilizar para evaluar el modelo.\n",
    "\n",
    "Lo más obvio que podemos hacer es comprobar el *accuracy* de las predicciones: en términos sencillos, ¿qué proporción de las etiquetas predijo correctamente el modelo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El *accuracy* se devuelve como un valor decimal: un valor de 1.0 significaría que el modelo acertó el 100% de las predicciones, mientras que una precisión de 0.0 es, bueno, eso no es muy útil\n",
    "\n",
    "En este notebook hemos preparado nuestros datos dividiéndolos en conjuntos de datos de prueba y de entrenamiento, y aplicado la regresión logística. \n",
    "\n",
    "Nuestro modelo fue capaz de predecir si los pacientes tenían diabetes con una precisión que parece razonable. Pero, ¿es suficiente? En el notebook ***02.Clasificacion_Metricas*** veremos alternativas a la precisión que pueden ser mucho más útiles en el aprendizaje automático.\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "conda-env-azureml_py38-py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
