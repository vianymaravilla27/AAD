{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analítica Avanzada de Datos.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación multiclase\n",
    "\n",
    "La clasificación multiclase puede considerarse como una combinación de varios clasificadores binarios. Hay dos formas de enfocar el problema:\n",
    "\n",
    "- **One vs Rest (OVR)**, en la que se crea un clasificador para cada posible valor de clase, con un resultado positivo para los casos en los que la predicción es esta clase, y predicciones negativas para los casos en los que la predicción es cualquier otra clase. Un problema de clasificación con cuatro clases de formas posibles (cuadrado, círculo, triángulo, hexágono) requeriría cuatro clasificadores que predijeran:\n",
    "    - *cuadrado* o no\n",
    "    - *círculo* o no\n",
    "    - *triángulo* o no\n",
    "    - *hexágono* o no\n",
    "\n",
    "    \n",
    "- **One vs One (OVO)**, en el que se crea un clasificador para cada par posible de clases. El problema de clasificación con cuatro clases de formas requeriría los siguientes clasificadores binarios:\n",
    "\n",
    "    - *cuadrado* o *círculo*\n",
    "    - *cuadrado* o *triángulo*\n",
    "    - *cuadrado* o *hexágono*\n",
    "    - *círculo* o *triángulo*\n",
    "    - *círculo* o *hexágono*\n",
    "    - *triángulo* o *hexágono*\n",
    "    \n",
    "En ambos enfoques, el modelo global que combina los clasificadores genera un vector de predicciones en el que las probabilidades generadas a partir de los clasificadores binarios individuales se utilizan para determinar qué clase predecir.\n",
    "\n",
    "> **Más Información**: Para obtener más información de los estimadores con la clasificación multiclase en Scikit-Learn, consulta el documento [Scikit-Learn documentation](https://scikit-learn.org/stable/modules/multiclass.html).\n",
    "\n",
    "### Explorar los datos¶\n",
    "\n",
    "Empecemos examinando un conjunto de datos que contenga observaciones de varias clases. Utilizaremos un conjunto de datos que contiene observaciones de tres especies diferentes de pingüinos.\n",
    "\n",
    "> **Cita**: El dataset de pingüinos utilizado en este ejercicio es un subconjunto de datos recogidos y puestos a disposición por la Dra. Kristen Gorman y la Estación Palmer, Antártida LTER, miembro de la Red de Investigación Ecológica a Largo Plazo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# cargar el conjunto de datos de entrenamiento\n",
    "penguins = pd.read_csv('penguins.csv')\n",
    "\n",
    "# Mostrar una muestra aleatoria de 10 observaciones\n",
    "sample = penguins.sample(10)\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset contiene las siguientes columnas\n",
    "\n",
    "* **CulmenLength**:  La longitud en mm del culmen (pico) del pingüino.\n",
    "* **CulmenDepth**: La profundidad en mm del culmen del pingüino.\n",
    "* **FlipperLength**: Longitud en mm de la aleta del pingüino.\n",
    "* **BodyMass**: La masa corporal del pingüino en gramos.\n",
    "* **Species**: Un valor entero que representa la especie del pingüino.\n",
    "\n",
    "La columna **Species**  es la clase para la que queremos entrenar un modelo de predicción. El dataset incluye tres especies posibles, que se codifican como 0, 1 y 2. Los nombres reales de las especies se revelan mediante el código siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "penguin_classes = ['Adelie', 'Gentoo', 'Chinstrap']\n",
    "print(sample.columns[0:5].values, 'SpeciesName')\n",
    "for index, row in penguins.sample(10).iterrows():\n",
    "    print('[',row[0], row[1], row[2], row[3], int(row[4]),']',penguin_classes[int(row[4])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que ya sabemos qué representan las características y las clases de los datos, vamos a explorar el dataset. En primer lugar, veamos si faltan valores (*null*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Contar el número de valores nulos de cada columna\n",
    "penguins.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que faltan algunos valores de características, pero no faltan clases. Profundicemos un poco más y veamos las filas que contienen nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mostrar filas que contengan nulos\n",
    "penguins[penguins.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay dos filas que no contienen ningún valor de característica (*NaN* significa \"not a number\", es decir, \"no es un número\"), por lo que no serán útiles para entrenar un modelo. Descartémoslas del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar filas que contengan valores NaN\n",
    "penguins=penguins.dropna()\n",
    "#Confirmar que ahora no hay nulos\n",
    "penguins.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que ya nos hemos ocupado de los valores que faltan, vamos a explorar cómo se relacionan las características con la etiqueta creando algunos gráficos de caja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "penguin_features = ['CulmenLength','CulmenDepth','FlipperLength','BodyMass']\n",
    "penguin_label = 'Species'\n",
    "for col in penguin_features:\n",
    "    penguins.boxplot(column=col, by=penguin_label, figsize=(6,6))\n",
    "    plt.title(col)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de los diagramas de caja, parece que las especies 0 y 2 (Adelie y Chinstrap) tienen perfiles de datos similares para la profundidad del culmen, la longitud de las aletas y la masa corporal, pero los Chinstraps tienden a tener culmos más largos. La especie 1 (Gentoo) tiende a tener características claramente diferenciadas de las demás, lo que debería ayudarnos a entrenar un buen modelo de clasificación.\n",
    "\n",
    "### Preparar los datos\n",
    "\n",
    "Al igual que para la clasificación binaria, antes de entrenar el modelo, tenemos que separar las características y la clase, y luego dividir los datos en subconjuntos para el entrenamiento y la validación. También aplicaremos una técnica de *estratificación* al dividir los datos para mantener la proporción de cada valor de clase en los datasets de entrenamiento y validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Características y clases separadas\n",
    "penguins_X, penguins_y = penguins[penguin_features].values, penguins[penguin_label].values\n",
    "\n",
    "# Dividir los datos 70%-30% en conjunto de entrenamiento y conjunto de prueba.\n",
    "x_penguin_train, x_penguin_test, y_penguin_train, y_penguin_test = train_test_split(penguins_X, penguins_y,\n",
    "                                                                                    test_size=0.30,\n",
    "                                                                                    random_state=0,\n",
    "                                                                                    stratify=penguins_y)\n",
    "\n",
    "print ('Training Set: %d, Test Set: %d \\n' % (x_penguin_train.shape[0], x_penguin_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenar y evaluar un clasificador multiclase\n",
    "\n",
    "Ahora que tenemos un conjunto de características de entrenamiento y las etiquetas de entrenamiento correspondientes, podemos ajustar un algoritmo de clasificación multiclase a los datos para crear un modelo. La mayoría de los algoritmos de clasificación de scikit-learn soportan intrínsecamente la clasificación multiclase. Probaremos con un algoritmo de regresión logística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Establecer la tasa de regularización\n",
    "reg = 0.1\n",
    "\n",
    "# entrenar un modelo de regresión logística en el conjunto de entrenamiento\n",
    "multi_model = LogisticRegression(C=1/reg, solver='lbfgs', multi_class='auto', max_iter=10000).fit(x_penguin_train, y_penguin_train)\n",
    "print (multi_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos utilizar el modelo entrenado para predecir las etiquetas de las características de prueba y comparar las clases predichas con las clases reales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "penguin_predictions = multi_model.predict(x_penguin_test)\n",
    "print('Predicted labels: ', penguin_predictions[:15])\n",
    "print('Actual labels   : ' ,y_penguin_test[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos un informe de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn. metrics import classification_report\n",
    "\n",
    "print(classification_report(y_penguin_test, penguin_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que con la clasificación binaria, el informe incluye métricas de *precisión* y *recall* para cada clase. Sin embargo, mientras que con la clasificación binaria podríamos centrarnos en las puntuaciones de la clase positiva; en este caso, hay múltiples clases, por lo que tenemos que mirar una métrica global (ya sea la macro o la media ponderada) para tener una idea de lo bien que el modelo se desempeña en las tres clases.\n",
    "\n",
    "Puede obtener las métricas globales por separado del informe utilizando las clases de puntuación de métricas de scikit-learn, pero con los resultados multiclase debe especificar qué métrica media desea utilizar para la precisión y recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "print(\"Overall Accuracy:\",accuracy_score(y_penguin_test, penguin_predictions))\n",
    "print(\"Overall Precision:\",precision_score(y_penguin_test, penguin_predictions, average='macro'))\n",
    "print(\"Overall Recall:\",recall_score(y_penguin_test, penguin_predictions, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos ahora la matriz de confusión de nuestro modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Imprimir la matriz de confusión\n",
    "mcm = confusion_matrix(y_penguin_test, penguin_predictions)\n",
    "print(mcm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz de confusión muestra la intersección entre los valores predichos y los valores reales de las clases para cada clase: en términos sencillos, las intersecciones diagonales de arriba a la izquierda indican el número de predicciones correctas.\n",
    "\n",
    "Cuando se trata de múltiples clases, suele ser más intuitivo visualizar esto como un mapa de calor, como éste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(mcm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(penguin_classes))\n",
    "plt.xticks(tick_marks, penguin_classes, rotation=45)\n",
    "plt.yticks(tick_marks, penguin_classes)\n",
    "plt.xlabel(\"Predicted Species\")\n",
    "plt.ylabel(\"Actual Species\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los cuadrados más oscuros en el gráfico de la matriz de confusión indican un gran número de casos, y es de esperar que pueda ver una línea diagonal de cuadrados más oscuros que indican los casos en los que la clase predicha y la real coinciden.\n",
    "\n",
    "En el caso de un modelo de clasificación multiclase, no es posible una curva ROC única que muestre la tasa de verdaderos positivos frente a la tasa de falsos positivos. Sin embargo, puede utilizar las tasas de cada clase en una comparación Uno contra Resto (OVR) para crear un gráfico ROC para cada clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Obtener puntuaciones de probabilidad de clase\n",
    "penguin_prob = multi_model.predict_proba(x_penguin_test)\n",
    "\n",
    "# Obtener métricas ROC para cada clase\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "thresh ={}\n",
    "for i in range(len(penguin_classes)):    \n",
    "    fpr[i], tpr[i], thresh[i] = roc_curve(y_penguin_test, penguin_prob[:,i], pos_label=i)\n",
    "    \n",
    "# Trazar el gráfico ROC\n",
    "plt.plot(fpr[0], tpr[0], linestyle='--',color='orange', label=penguin_classes[0] + ' vs Rest')\n",
    "plt.plot(fpr[1], tpr[1], linestyle='--',color='green', label=penguin_classes[1] + ' vs Rest')\n",
    "plt.plot(fpr[2], tpr[2], linestyle='--',color='blue', label=penguin_classes[2] + ' vs Rest')\n",
    "plt.title('Multiclass ROC curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive rate')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cuantificar el rendimiento ROC, puede calcular una puntuación agregada del área bajo la curva que se promedia en todas las curvas OVR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = roc_auc_score(y_penguin_test,penguin_prob, multi_class='ovr')\n",
    "print('Average AUC:', auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento de datos en un pipeline\n",
    "\n",
    "De nuevo, al igual que con la clasificación binaria, puede utilizar un pipeline para aplicar pasos de preprocesamiento a los datos antes de ajustarlos a un algoritmo para entrenar un modelo. Veamos si podemos mejorar el predictor pingüino escalando las características numéricas en un paso de transformación antes del entrenamiento. También probaremos un algoritmo diferente (una máquina de soporte vectorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Definir preprocesamiento para columnas numéricas (escalarlas)\n",
    "feature_columns = [0,1,2,3]\n",
    "feature_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "# Crear pasos de preprocesamiento\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('preprocess', feature_transformer, feature_columns)])\n",
    "\n",
    "# Crear pipeline de entrenamiento\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regressor', SVC(probability=True))])\n",
    "\n",
    "\n",
    "# ajustar el pipeline para entrenar un modelo de regresión lineal en el conjunto de entrenamiento\n",
    "multi_model = pipeline.fit(x_penguin_train, y_penguin_train)\n",
    "print (multi_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos evaluar el nuevo modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Obtener predicciones a partir de datos de prueba\n",
    "penguin_predictions = multi_model.predict(x_penguin_test)\n",
    "penguin_prob = multi_model.predict_proba(x_penguin_test)\n",
    "\n",
    "# Métricas generales\n",
    "print(\"Overall Accuracy:\",accuracy_score(y_penguin_test, penguin_predictions))\n",
    "print(\"Overall Precision:\",precision_score(y_penguin_test, penguin_predictions, average='macro'))\n",
    "print(\"Overall Recall:\",recall_score(y_penguin_test, penguin_predictions, average='macro'))\n",
    "print('Average AUC:', roc_auc_score(y_penguin_test,penguin_prob, multi_class='ovr'))\n",
    "\n",
    "# Matriz de confusión\n",
    "plt.imshow(mcm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(penguin_classes))\n",
    "plt.xticks(tick_marks, penguin_classes, rotation=45)\n",
    "plt.yticks(tick_marks, penguin_classes)\n",
    "plt.xlabel(\"Predicted Species\")\n",
    "plt.ylabel(\"Actual Species\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizar el modelo con nuevas observaciones de datos\n",
    "\n",
    "Ahora vamos a guardar nuestro modelo entrenado para poder volver a utilizarlo más adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Guardar el modelo como un archivo pickle\n",
    "filename = 'penguin_model.pkl'\n",
    "joblib.dump(multi_model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Ya tenemos un modelo entrenado. Usémoslo para predecir la clase de una nueva observación de un pingüino:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cargar el modelo desde el archivo\n",
    "multi_model = joblib.load(filename)\n",
    "\n",
    "# El modelo acepta una matriz de matrices de características (para que pueda predecir las clases de múltiples observaciones de pingüinos en una sola llamada)\n",
    "# Crearemos un array con un único array de características, representando un pingüino\n",
    "x_new = np.array([[50.4,15.3,224,5550]])\n",
    "print ('New sample: {}'.format(x_new[0]))\n",
    "\n",
    "# El modelo devuelve una matriz de predicciones - una para cada conjunto de características presentadas\n",
    "# En nuestro caso, sólo hemos enviado un pingüino, por lo que nuestra predicción es la primera en la matriz resultante.\n",
    "penguin_pred = multi_model.predict(x_new)[0]\n",
    "print('Predicted class is', penguin_classes[penguin_pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También puedes enviar un lote de observaciones de pingüinos al modelo y obtener una predicción para cada una de ellas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Esta vez nuestra entrada es una matriz de dos matrices de características\n",
    "x_new = np.array([[49.5,18.4,195, 3600],\n",
    "         [38.2,20.1,190,3900]])\n",
    "print ('New samples:\\n{}'.format(x_new))\n",
    "\n",
    "predictions = multi_model.predict(x_new)\n",
    "\n",
    "# Obtener las clases predichas.\n",
    "for prediction in predictions:\n",
    "    print(prediction, '(' + penguin_classes[prediction] +')')"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "conda-env-azureml_py38-py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
